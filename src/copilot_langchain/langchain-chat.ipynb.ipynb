{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import openai\n",
    "from typing import Any, List\n",
    "#from langchain import PromptTemplate\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.chat_models import AzureChatOpenAI\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain.chains import ConversationalRetrievalChain\n",
    "from azure.ai.generative.index import get_langchain_retriever_from_index\n",
    "\n",
    "from langchain.retrievers import AzureCognitiveSearchRetriever\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain.vectorstores.azuresearch import AzureSearch\n",
    "from langchain.vectorstores import FAISS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set credential values needed to authenciate and authorize access to your Azure OpenAI instance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup_credentials():\n",
    "    # Azure OpenAI credentials\n",
    "    openai.api_type = os.environ[\"OPENAI_API_TYPE\"]\n",
    "    openai.api_key = os.environ[\"OPENAI_API_KEY\"]\n",
    "    openai.api_version = os.environ[\"OPENAI_API_VERSION\"]\n",
    "    openai.api_base = os.environ[\"OPENAI_API_BASE\"]\n",
    "\n",
    "    # Azure Cognitive Search credentials\n",
    "    os.environ[\"AZURE_COGNITIVE_SEARCH_TARGET\"] = os.environ[\"AZURE_AI_SEARCH_ENDPOINT\"]\n",
    "    os.environ[\"AZURE_COGNITIVE_SEARCH_API_KEY\"] = os.environ[\"AZURE_AI_SEARCH_KEY\"]\n",
    "    os.environ[\"AZURE_COGNITIVE_SEARCH_SERVICE_NAME\"] = \"search-ai-aiprog-hub\" #\"AzureAISearch\"\n",
    "    os.environ[\"AZURE_COGNITIVE_SEARCH_INDEX_NAME\"] = os.environ[\"AZURE_AI_SEARCH_INDEX_NAME\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Execute the authorize with the given credentials above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "setup_credentials()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.retrievers import AzureCognitiveSearchRetriever\n",
    "retriever = AzureCognitiveSearchRetriever(content_key=\"content\", top_k=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set you cognitive search endpoint and key for the vector store"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the AzureSearch instance with the OpenAIEmbeddings to vectorize the input sample text data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Construct your prompt by specifying what the chat assistant does as well as the scope and domain of topics it can provide information for.  In addition, define any constraints, restricts or bounderies on how the prompt show behave.  The prompt template includes action the prompt can take; chat history of the system/user dialogue; context of the chat conversation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "template = \"\"\"\n",
    "System:\n",
    "You are an AI assistant helping users with queries related to outdoor outdooor/camping gear and clothing.\n",
    "Use the following pieces of context to answer the questions about outdoor/camping gear and clothing as completely, correctly, and concisely as possible.\n",
    "\n",
    "---\n",
    "\n",
    "{chat_history}\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "Question: {question}\n",
    "\n",
    "Answer:\"\n",
    "\"\"\"\n",
    "\n",
    "prompt_template = PromptTemplate(\n",
    "    template=template,\n",
    "    input_variables=[\n",
    "        \"context\",\n",
    "        \"chat_history\",\n",
    "        \"question\"\n",
    "    ],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "memory = ConversationBufferMemory(memory_key=\"chat_history\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialize the AzureChatOpenAI instance with your Azure Open AI model and deployment.  The temperature value ranges from 0 to 1.  Value close to 0 denote how specific you want the response to be and value close to 1 denote how randomly you want the responses to be."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = AzureChatOpenAI(\n",
    "    deployment_name=os.environ[\"AZURE_OPENAI_CHAT_DEPLOYMENT\"],\n",
    "    model_name=os.environ[\"AZURE_OPENAI_CHAT_MODEL\"],\n",
    "    temperature=0.7\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, you can ready to invoke the key of langchain you want to use.  <provide the type of conversion you want>.  To activate the instance you need your LLM model to retrieve response, the promt template including the rules, and verbose <???>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ActivityStarted, MLIndex.__init__\n",
      "ActivityCompleted: Activity=MLIndex.__init__, HowEnded=Success, Duration=25.11 [ms]\n",
      "ActivityStarted, MLIndex.as_langchain_vectorstore\n",
      "azure-search-documents==11.4.0b11 not compatible langchain.vectorstores.azuresearch yet, using REST client based VectorStore.\n",
      "ActivityCompleted: Activity=MLIndex.as_langchain_vectorstore, HowEnded=Success, Duration=38.82 [ms]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/workspaces/aistudio-copilot-sample/product-info-mlindex\n",
      "tags=['AzureCognitiveSearchVectorStore'] vectorstore=<azure.ai.generative.index._langchain.acs.AzureCognitiveSearchVectorStore object at 0x7f612cec34f0>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\n\\nqna_chain =RetrievalQA.from_chain_type(\\n    llm=llm,\\n    chain_type=\"stuff\",\\n    retriever=index_langchain_retriever,\\n    #retriever=retriever,\\n    return_source_documents=True,\\n    chain_type_kwargs={\\n        \"prompt\": prompt_template,\\n    }\\n    \\n)\\n'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# convert MLIndex to a langchain retriever\n",
    "search_index_folder = os.getenv(\"AZURE_AI_SEARCH_INDEX_NAME\") + \"-mlindex\"\n",
    "index_langchain_retriever = get_langchain_retriever_from_index(search_index_folder)\n",
    "\n",
    "print(search_index_folder)\n",
    "print(index_langchain_retriever)\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "qna_chain =RetrievalQA.from_chain_type(\n",
    "    llm=llm,\n",
    "    chain_type=\"stuff\",\n",
    "    retriever=index_langchain_retriever,\n",
    "    #retriever=retriever,\n",
    "    return_source_documents=True,\n",
    "    chain_type_kwargs={\n",
    "        \"prompt\": prompt_template,\n",
    "    }\n",
    "    \n",
    ")\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "memory = ConversationBufferMemory(memory_key=\"chat_history\", return_messages=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tags=['AzureCognitiveSearchVectorStore'] vectorstore=<azure.ai.generative.index._langchain.acs.AzureCognitiveSearchVectorStore object at 0x7f612cec34f0>\n"
     ]
    }
   ],
   "source": [
    "vectorstore = index_langchain_retriever\n",
    "print(vectorstore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "qna_chain = ConversationalRetrievalChain.from_llm(llm=llm,\n",
    "                                           retriever=retriever,\n",
    "                                           condense_question_prompt=prompt_template,\n",
    "                                           #return_source_documents=True,\n",
    "                                           verbose=False,\n",
    "                                           memory=memory)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's test the chat with a question!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Based on the available information, both the Alpine Explorer Tent (item_number: 8) and the SkyView 2-Person Tent (item_number: 15) are described as waterproof in the reviews. However, there is no specific comparison provided to determine which tent is more waterproof.'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#when you want to initalize chat with history.\n",
    "\n",
    "\n",
    "\n",
    "inquiry = \"which tent is the most waterproof?\"\n",
    "response = qna_chain({\"question\": inquiry})\n",
    "response['answer']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
